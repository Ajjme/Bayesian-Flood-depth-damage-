{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIUKWV9riHUv1TpTYEdcxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajjme/Bayesian-Flood-depth-damage-/blob/main/Bayesian_depth_damage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEj32eGuWdTz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian depth-damage example\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import pytensor.tensor as pt\n",
        "\n",
        "# -------------------------\n",
        "# 1) define parametric form\n",
        "# -------------------------\n",
        "def curve(depth, alpha, beta):\n",
        "    return 1 - np.exp(-alpha * np.power(depth, beta))\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 2) synthetic Army Corps \"table\"\n",
        "# -------------------------\n",
        "alpha_ac_true = 0.35\n",
        "beta_ac_true  = 1.6\n",
        "depth_grid_ac = np.linspace(0, 5.0, 41)\n",
        "rng = np.random.default_rng(123)\n",
        "damage_ac_true = curve(depth_grid_ac, alpha_ac_true, beta_ac_true)\n",
        "# add tiny noise to simulate tabulated empirical curve\n",
        "damage_ac_table = np.clip(damage_ac_true + rng.normal(scale=0.01, size=damage_ac_true.shape), 0, 1)\n",
        "army_df = pd.DataFrame({'depth': depth_grid_ac, 'damage_frac': damage_ac_table})\n",
        "depth_acoe = army_df[\"depth\"].values\n",
        "damage_acoe = army_df[\"damage_frac\"].values\n",
        "\n",
        "popt, pcov = curve_fit(curve, depth_acoe, damage_acoe, bounds=(0, np.inf))\n",
        "alpha_ac, beta_ac = popt\n",
        "alpha_sd, beta_sd = np.sqrt(np.diag(pcov))\n",
        "\n",
        "# quick plot\n",
        "plt.figure()\n",
        "plt.plot(depth_grid_ac, damage_ac_true, label='Underlying true param curve', lw=2)\n",
        "plt.scatter(army_df['depth'], army_df['damage_frac'], label='Army table (synthetic)', zorder=3)\n",
        "plt.xlabel('Depth (m)')\n",
        "plt.ylabel('Damage fraction')\n",
        "plt.legend()\n",
        "plt.title('Synthetic Army Corps curve (table)')\n",
        "plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# 3) synthetic state observations\n",
        "# -------------------------\n",
        "n_states = 8\n",
        "state_names = [f\"State_{i+1}\" for i in range(n_states)]\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# true state-specific parameters (unknown to model)\n",
        "alpha_state_true = alpha_ac_true * (1 + rng.normal(0.0, 0.25, size=n_states))\n",
        "beta_state_true  = beta_ac_true  * (1 + rng.normal(0.0, 0.15, size=n_states))\n",
        "\n",
        "rows = []\n",
        "for s_idx, s in enumerate(state_names):\n",
        "    n_obs = rng.integers(30, 120)  # variable sample size per state\n",
        "    depths = rng.uniform(0.05, 4.8, size=n_obs)\n",
        "    mu = curve(depths, alpha_state_true[s_idx], beta_state_true[s_idx])\n",
        "    # heteroskedastic noise (bigger absolute noise for larger damage)\n",
        "    obs_noise = rng.normal(scale=0.04 + 0.12 * mu, size=n_obs)\n",
        "    y = np.clip(mu + obs_noise, 0.0, 1.0)\n",
        "    # small chance of underreporting tiny damages\n",
        "    under_report_mask = (rng.random(n_obs) < 0.03) & (y < 0.15)\n",
        "    y[under_report_mask] = y[under_report_mask] * rng.uniform(0.1, 0.4, size=under_report_mask.sum())\n",
        "    for di, yi in zip(depths, y):\n",
        "        rows.append({'state': s, 'depth': di, 'damage_frac': yi})\n",
        "\n",
        "state_df = pd.DataFrame(rows)\n",
        "state_df['state_id'] = state_df['state'].astype('category').cat.codes\n",
        "\n",
        "#new # --- ensure army table has no exact 0/1 (you already clipped a little earlier, but be safe)\n",
        "army_df['damage_frac'] = army_df['damage_frac'].clip(1e-6, 1 - 1e-6)\n",
        "\n",
        "# --- ensure observed data are strictly inside (0,1) to be valid for Beta likelihood\n",
        "state_df['damage_frac'] = state_df['damage_frac'].clip(1e-6, 1 - 1e-6)\n",
        "\n",
        "# quick sanity check (helpful if you get the same error again)\n",
        "if not np.isfinite(state_df['damage_frac']).all():\n",
        "    raise ValueError(\"Non-finite damage_frac present\")\n",
        "if ((state_df['damage_frac'] <= 0).any() or (state_df['damage_frac'] >= 1).any()):\n",
        "    print(\"Warning: some damage_frac are exactly 0 or 1; they've been clipped.\")\n",
        "print(\"Total observations:\", len(state_df))\n",
        "print(\"Observations per state (sample):\")\n",
        "print(state_df.groupby('state').size().sort_values(ascending=False).head())\n",
        "\n",
        "# plot sample states\n",
        "plt.figure(figsize=(10,6))\n",
        "for s in state_names[:4]:\n",
        "    dsub = state_df[state_df['state'] == s]\n",
        "    plt.scatter(dsub['depth'], dsub['damage_frac'], s=10, alpha=0.4, label=s)\n",
        "plt.xlabel('Depth (m)')\n",
        "plt.ylabel('Damage fraction')\n",
        "plt.legend()\n",
        "plt.title('Sample of state observations (first 4 states)')\n",
        "plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# 4) fit Army Corps curve to get priors\n",
        "# -------------------------\n",
        "popt, pcov = curve_fit(curve, army_df['depth'].values, army_df['damage_frac'].values, bounds=(0, np.inf))\n",
        "alpha_ac_fit, beta_ac_fit = popt\n",
        "alpha_ac_sd, beta_ac_sd = np.sqrt(np.diag(pcov))\n",
        "print(f'Fitted Army Corps parameters: alpha = {alpha_ac_fit:.4f} ± {alpha_ac_sd:.4f}, beta = {beta_ac_fit:.4f} ± {beta_ac_sd:.4f}')\n",
        "\n",
        "# -------------------------\n",
        "# 5) build hierarchical PyMC model\n",
        "# -------------------------\n",
        "d = state_df['depth'].values\n",
        "y = state_df['damage_frac'].values\n",
        "state_ids = state_df['state_id'].values\n",
        "n_states = state_df['state_id'].nunique()\n",
        "\n",
        "# inflate the fitted SDs a bit to avoid overconfident priors\n",
        "alpha_prior_sd = max(alpha_ac_sd * 3, 0.5 * alpha_ac_fit)\n",
        "beta_prior_sd  = max(beta_ac_sd * 3, 0.2 * abs(beta_ac_fit))\n",
        "\n",
        "with pm.Model() as model:\n",
        "\n",
        "    # Hyperpriors centered on generic ACOE values\n",
        "    mu_alpha = pm.Normal(\"mu_alpha\", mu=alpha_ac, sigma=alpha_sd)\n",
        "    sigma_alpha = pm.HalfNormal(\"sigma_alpha\", sigma=1.0)\n",
        "\n",
        "    mu_beta = pm.Normal(\"mu_beta\", mu=beta_ac, sigma=beta_sd)\n",
        "    sigma_beta = pm.HalfNormal(\"sigma_beta\", sigma=1.0)\n",
        "\n",
        "    # State-level alpha (must be positive)\n",
        "    raw_alpha = pm.Normal(\"raw_alpha\", mu=0, sigma=1, shape=n_states)\n",
        "    alpha_state = pm.Deterministic(\n",
        "        \"alpha_state\",\n",
        "        pt.softplus(mu_alpha + raw_alpha * sigma_alpha)\n",
        "    )\n",
        "\n",
        "    # State-level beta (shape parameter)\n",
        "    beta_state = pm.Normal(\"beta_state\", mu=mu_beta, sigma=sigma_beta, shape=n_states)\n",
        "\n",
        "    # Dispersion parameter for Beta likelihood\n",
        "    kappa = pm.Exponential(\"kappa\", lam=1.0)\n",
        "\n",
        "    # Compute mean damage safely\n",
        "    depth_pow = pt.power(d, beta_state[state_ids])      # safe exponentiation\n",
        "    arg = -alpha_state[state_ids] * depth_pow\n",
        "    arg = pt.clip(arg, -50, 50)                         # prevent overflow\n",
        "\n",
        "    mu = 1 - pt.exp(arg)\n",
        "    mu = pt.clip(mu, 1e-6, 1 - 1e-6)                    # keep in (0,1)\n",
        "\n",
        "    # Likelihood\n",
        "    pm.Beta(\"y_obs\",\n",
        "            alpha=mu * kappa,\n",
        "            beta=(1 - mu) * kappa,\n",
        "            observed=y)\n",
        "\n",
        "    trace = pm.sample(\n",
        "    tune=500,      # fewer tuning steps\n",
        "    draws=500,     # fewer posterior draws\n",
        "    chains=2,      # default is usually 4; fewer chains = faster\n",
        "    target_accept=0.9,\n",
        "    random_seed=123\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 6) posterior diagnostics & summary\n",
        "# -------------------------\n",
        "az.plot_trace(trace, var_names=['mu_alpha', 'mu_beta', 'sigma_alpha', 'sigma_beta', 'kappa'])\n",
        "plt.show()\n",
        "\n",
        "print(az.summary(trace, var_names=['mu_alpha', 'mu_beta', 'sigma_alpha', 'sigma_beta', 'kappa'], round_to=2))\n",
        "\n",
        "# -------------------------\n",
        "# 7) posterior-predictive checks (manual plotting)\n",
        "# -------------------------\n",
        "with model:\n",
        "    ppc = pm.sample_posterior_predictive(trace, random_seed=123)\n",
        "\n",
        "# The result is an xarray DataArray with shape (chain, draw, n_observations)\n",
        "# Example shape: (2, 500, 700) -> 2 chains, 500 draws, 700 observations\n",
        "ppc_samples_xarray = ppc.posterior_predictive['y_obs']\n",
        "ppc_samples = ppc_samples_xarray.values\n",
        "\n",
        "# Calculate the total number of samples (population size for choice)\n",
        "chains = ppc_samples.shape[0]\n",
        "draws = ppc_samples.shape[1]\n",
        "n_total_samples = chains * draws\n",
        "\n",
        "# Reshape the array to (n_total_samples, n_observations)\n",
        "ppc_samples_flat = ppc_samples.reshape(n_total_samples, -1)\n",
        "\n",
        "# --- Your original code resumes here, using the flattened array ---\n",
        "# ppc_samples_flat has shape (1000, N_observations)\n",
        "\n",
        "# pick a few random posterior predictive draws to plot\n",
        "n_plot = 20\n",
        "# Now the population size is ppc_samples_flat.shape[0] = 1000, which is > 20.\n",
        "idx = np.random.choice(ppc_samples_flat.shape[0], n_plot, replace=False)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "for i in idx:\n",
        "    plt.scatter(state_df['depth'], ppc_samples_flat[i], s=10, alpha=0.3, color='blue')\n",
        "# overlay observed data\n",
        "plt.scatter(state_df['depth'], state_df['damage_frac'], s=15, alpha=0.6, color='red', label='Observed')\n",
        "plt.xlabel('Depth (m)')\n",
        "plt.ylabel('Damage fraction')\n",
        "plt.title('Posterior predictive check (sample draws)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 8) compute updated curves per state\n",
        "# -------------------------\n",
        "# get flattened posterior samples for state-level params\n",
        "posterior = trace.posterior  # xarray dataset, dims: chain, draw, [state dim]\n",
        "# reshape to (n_samples, n_states)\n",
        "chains, draws = posterior.sizes['chain'], posterior.sizes['draw']\n",
        "n_samples = chains * draws\n",
        "alpha_samples = posterior['alpha_state'].values.reshape(n_samples, n_states)\n",
        "beta_samples  = posterior['beta_state'].values.reshape(n_samples, n_states)\n",
        "\n",
        "depth_grid = np.linspace(0, 5.0, 200)\n",
        "summary_curves = {}\n",
        "\n",
        "for s in range(n_states):\n",
        "    a_s = alpha_samples[:, s]   # shape (n_samples,)\n",
        "    b_s = beta_samples[:, s]    # shape (n_samples,)\n",
        "    # compute preds for all posterior samples: shape (n_samples, len(depth_grid))\n",
        "    preds = 1 - np.exp(-np.outer(a_s, depth_grid**1.0) * (depth_grid**(b_s.reshape(-1,1)-1.0)))\n",
        "    # simpler correct computation\n",
        "    # preds = 1 - np.exp(-a_s[:,None] * depth_grid[None,:]**b_s[:,None])\n",
        "    # the above two approaches are equivalent; using direct broadcasting below:\n",
        "    preds = 1 - np.exp(-a_s[:, None] * (depth_grid[None, :] ** b_s[:, None]))\n",
        "    mean_curve = preds.mean(axis=0)\n",
        "    lo = np.percentile(preds, 2.5, axis=0)\n",
        "    hi = np.percentile(preds, 97.5, axis=0)\n",
        "    summary_curves[s] = {'mean': mean_curve, 'lo': lo, 'hi': hi}\n",
        "\n",
        "# -------------------------\n",
        "# 9) plot a few states vs Army generic\n",
        "# -------------------------\n",
        "for s in range(min(6, n_states)):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(depth_grid, summary_curves[s]['mean'], label=f'Posterior mean (State {s})', lw=2)\n",
        "    plt.fill_between(depth_grid, summary_curves[s]['lo'], summary_curves[s]['hi'], alpha=0.25)\n",
        "    plt.plot(depth_grid, curve(depth_grid, alpha_ac_fit, beta_ac_fit), '--', label='ACOE generic (fitted)', color='k')\n",
        "    # overlay observed points for that state\n",
        "    mask = state_df['state_id'] == s\n",
        "    plt.scatter(state_df.loc[mask, 'depth'], state_df.loc[mask, 'damage_frac'], s=10, alpha=0.4, label='observations')\n",
        "    plt.xlabel('Depth (m)')\n",
        "    plt.ylabel('Damage fraction')\n",
        "    plt.title(f'Updated depth–damage: State {s} (n_obs={mask.sum()})')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# 10) Save results\n",
        "# -------------------------\n",
        "# army_df.to_csv('army_corps_synthetic_curve.csv', index=False)\n",
        "# state_df.to_csv('state_synthetic_observations.csv', index=False)\n",
        "# print(\"Saved synthetic CSVs: army_corps_synthetic_curve.csv, state_synthetic_observations.csv\")\n"
      ],
      "metadata": {
        "id": "756X4rUoWd5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}